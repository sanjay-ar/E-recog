{"ast":null,"code":"var _s = $RefreshSig$(),\n    _s2 = $RefreshSig$(),\n    _s3 = $RefreshSig$(),\n    _s4 = $RefreshSig$(),\n    _s5 = $RefreshSig$(),\n    _s6 = $RefreshSig$();\n\nimport { useAppDispatch, useAppSelector } from \"../../reduxHooks\";\nimport { useCallback, useEffect, useLayoutEffect, useRef, useState } from \"react\";\nimport ScreenCaptureService from \"../../media/ScreenCaptureService\";\nimport { fetchMeeting, setActiveMeeting } from \"../../meetings/meetingsSlice\";\nimport { unwrapResult } from \"@reduxjs/toolkit\";\nimport FaceRecognitionService from \"../../meetings/FaceRecognitionService\";\nimport { addFaceExpressionScore } from \"../../meetings/audienceFaceExpressionSlice\";\nimport { aggregateAndCalculateExpressionScore, aggregateAndCalculatePaulEkmanEmotionScore } from \"../../meetings/audienceFaceExpressionUtils\";\nimport { addError } from \"../../error/errorSlice\";\nimport { activeMeetingEnded, activeMeetingRunning, selectMeetingById } from \"../../meetings/meetingsSelectors\";\nimport VoiceCaptureService from \"../../media/VoiceCaptureService\";\nimport { rmsNormalize, softmax } from \"../../utils\";\nimport { aggregateAndCalculateVoiceEmotionScore, VOICE_EMOTIONS } from \"../../meetings/speakerVoiceEmotionUtils\";\nimport { addVoiceEmotionScore } from \"../../meetings/speakerVoiceEmotionSlice\"; // onnxruntime-web is included in public/index.html as <script>\n// .wasm files are currently not compatible with the create-react-app webpack config\n\nconst InferenceSession = window.ort.InferenceSession;\nconst Tensor = window.ort.Tensor; // Returns a callback to start the screen capturing and automatically cleans up the react components.\n// Does nothing if the meeting is stopped.\n// Note: In Safari you must start a screen capturing from a user gesture handler. This means that\n// you cannot ask for permissions immediately after loading the page. The user must explicitly click a button\n// to agree that he will be asked for permission.\n\nexport function useScreenCapturingIfMeetingIsRunning(videoRef, handleStopMeeting) {\n  _s();\n\n  const dispatch = useAppDispatch();\n  const screenCaptureServiceRef = useRef();\n  const meetingRunning = useAppSelector(activeMeetingRunning);\n  const startScreenCapturing = useCallback(async () => {\n    if (meetingRunning) {\n      try {\n        screenCaptureServiceRef.current = new ScreenCaptureService();\n        await screenCaptureServiceRef.current.startCapturing();\n        await screenCaptureServiceRef.current.attachStreamToVideo(videoRef.current);\n        screenCaptureServiceRef.current.mediaStream.getTracks()[0].addEventListener(\"ended\", handleStopMeeting);\n      } catch (e) {\n        dispatch(addError(\"Cannot start screen capturing: \" + e.message + \". Try to reload the page.\"));\n      }\n    }\n  }, [dispatch, handleStopMeeting, meetingRunning, videoRef]); // Cleanup function\n\n  useEffect(() => {\n    return () => {\n      var _screenCaptureService;\n\n      (_screenCaptureService = screenCaptureServiceRef.current) === null || _screenCaptureService === void 0 ? void 0 : _screenCaptureService.stopCapturing();\n    };\n  }, [meetingRunning]);\n  return startScreenCapturing;\n}\n\n_s(useScreenCapturingIfMeetingIsRunning, \"iZwKDjxOeYLl8IVAb+/XPe/trok=\", false, function () {\n  return [useAppDispatch, useAppSelector];\n});\n\nexport function useEmotionDetection(videoRef, canvasRef) {\n  _s2();\n\n  const dispatch = useAppDispatch();\n  const meetingRunning = useAppSelector(activeMeetingRunning);\n  const meetingID = useAppSelector(state => state.meetings.activeMeeting);\n  const detectionsRef = useRef([]);\n  const faceRecognitionServiceRef = useRef(); // Initialize the face recognition service\n\n  useEffect(() => {\n    const initializeFaceDetection = async () => {\n      faceRecognitionServiceRef.current = new FaceRecognitionService(videoRef.current);\n      await faceRecognitionServiceRef.current.loadModel();\n    };\n\n    initializeFaceDetection();\n  }, [videoRef]); // Perform the detections every second\n\n  useEffect(() => {\n    let interval;\n\n    const syncDetections = async () => {\n      if (meetingRunning) {\n        try {\n          interval = window.setInterval(async () => {\n            await faceRecognitionServiceRef.current.detectAllFaces().then(detections => detectionsRef.current = detections);\n\n            if (detectionsRef.current.length > 0) {\n              await dispatch(addFaceExpressionScore({\n                score: aggregateAndCalculateExpressionScore(detectionsRef.current),\n                raw: aggregateAndCalculatePaulEkmanEmotionScore(detectionsRef.current),\n                meetingID\n              }));\n            }\n          }, 1000);\n        } catch (e) {\n          await dispatch(addError(\"Error while trying to save detected emotions: \" + e.message));\n        }\n      }\n    };\n\n    syncDetections();\n    return () => {\n      clearInterval(interval);\n    };\n  }, [dispatch, meetingID, meetingRunning]); // Draw the most recent detections with a high frame rate\n\n  useLayoutEffect(() => {\n    let animationFrame;\n\n    if (meetingRunning) {\n      const drawDetections = () => {\n        if (!!canvasRef.current) {\n          faceRecognitionServiceRef.current.drawDetections(detectionsRef.current, canvasRef.current);\n        }\n\n        animationFrame = requestAnimationFrame(drawDetections);\n      };\n\n      animationFrame = requestAnimationFrame(drawDetections);\n      return () => {\n        var _canvasRef$current, _canvasRef$current$ge;\n\n        cancelAnimationFrame(animationFrame);\n        (_canvasRef$current = canvasRef.current) === null || _canvasRef$current === void 0 ? void 0 : (_canvasRef$current$ge = _canvasRef$current.getContext(\"2d\") // eslint-disable-next-line react-hooks/exhaustive-deps\n        ) === null || _canvasRef$current$ge === void 0 ? void 0 : _canvasRef$current$ge. // eslint-disable-next-line react-hooks/exhaustive-deps\n        clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);\n      };\n    }\n  }, [canvasRef, meetingRunning]);\n}\n\n_s2(useEmotionDetection, \"muJCmkfbzF/TQr/ON3suO1f/PIo=\", false, function () {\n  return [useAppDispatch, useAppSelector, useAppSelector];\n});\n\nexport function useFetchMeeting(id) {\n  _s3();\n\n  const dispatch = useAppDispatch();\n  const [notFound, setNotFound] = useState(false);\n  useEffect(() => {\n    const fetch = async () => {\n      const result = await dispatch(fetchMeeting(id));\n      const meeting = unwrapResult(result);\n\n      if (!meeting) {\n        setNotFound(true);\n      } else {\n        dispatch(setActiveMeeting(meeting.id));\n        setNotFound(false);\n      }\n    };\n\n    fetch();\n    return () => {\n      dispatch(setActiveMeeting(null));\n    };\n  }, [dispatch, id]);\n  return [notFound];\n}\n\n_s3(useFetchMeeting, \"8a9LjtNhh43o8ZQJ57atKxhg8FM=\", false, function () {\n  return [useAppDispatch];\n});\n\nexport function useMeetingInformation(id) {\n  _s4();\n\n  const meetingRunning = useAppSelector(activeMeetingRunning);\n  const meetingEnded = useAppSelector(activeMeetingEnded);\n  const meetingLoading = useAppSelector(state => state.meetings.loading);\n  const meetingName = useAppSelector(state => {\n    var _selectMeetingById;\n\n    return (_selectMeetingById = selectMeetingById(state, id)) === null || _selectMeetingById === void 0 ? void 0 : _selectMeetingById.name;\n  });\n  return [meetingLoading, meetingRunning, meetingEnded, meetingName];\n}\n\n_s4(useMeetingInformation, \"527JMQxYcpZ/dJEqY5AX6TK7k4I=\", false, function () {\n  return [useAppSelector, useAppSelector, useAppSelector, useAppSelector];\n});\n\nexport function useVoiceCapturingIfMeetingIsRunning(callback) {\n  _s5();\n\n  const voiceCaptureServiceRef = useRef(null);\n  const dispatch = useAppDispatch();\n  const meetingRunning = useAppSelector(activeMeetingRunning);\n  const startVoiceCapturing = useCallback(async audioDevice => {\n    voiceCaptureServiceRef.current = new VoiceCaptureService();\n\n    try {\n      var _voiceCaptureServiceR, _voiceCaptureServiceR2;\n\n      await voiceCaptureServiceRef.current.startCapturing(audioDevice);\n      (_voiceCaptureServiceR = voiceCaptureServiceRef.current) === null || _voiceCaptureServiceR === void 0 ? void 0 : _voiceCaptureServiceR.startAnalyzer(callback);\n      return (_voiceCaptureServiceR2 = voiceCaptureServiceRef.current) === null || _voiceCaptureServiceR2 === void 0 ? void 0 : _voiceCaptureServiceR2.mediaStream;\n    } catch (e) {\n      dispatch(addError(\"Cannot start voice capturing: \" + e.message + \". Try to reload the page.\"));\n    }\n  }, [callback, dispatch]);\n  const stopVoiceCapturing = useCallback(async () => {\n    try {\n      var _voiceCaptureServiceR3;\n\n      await ((_voiceCaptureServiceR3 = voiceCaptureServiceRef.current) === null || _voiceCaptureServiceR3 === void 0 ? void 0 : _voiceCaptureServiceR3.stopCapturing());\n    } catch (e) {\n      dispatch(addError(e.message));\n    }\n\n    voiceCaptureServiceRef.current = null;\n  }, [dispatch]); // Auto cleanup on component unmount or if the meeting is stopped\n\n  useEffect(() => {\n    return () => {\n      stopVoiceCapturing();\n    };\n  }, [meetingRunning, stopVoiceCapturing]);\n  return [startVoiceCapturing, stopVoiceCapturing];\n}\n\n_s5(useVoiceCapturingIfMeetingIsRunning, \"RFwx5makQVzbwSQH10J1gZkctNI=\", false, function () {\n  return [useAppDispatch, useAppSelector];\n});\n\nexport function useVoiceEmotionCapturing() {\n  _s6();\n\n  const onnxSession = useRef(null);\n  const warmupModel = useCallback(async () => {\n    onnxSession.current = await InferenceSession.create(\"/onnx/voice_emotion_cnn.onnx\", {\n      executionProviders: [\"wasm\"]\n    });\n  }, []);\n  const dispatch = useAppDispatch();\n  const meetingID = useAppSelector(state => state.meetings.activeMeeting); // Create a buffer for the audio data.\n  // This gets flushed every 2.1 seconds by the callback.\n\n  let dataRef = useRef([]); // Audio data below this threshold will be considered as silence\n  // This is useful to exclude disturbing background noises for example\n\n  const THRESHOLD_RMS = 0.002; // Gets the features extracted by the audio analyzer (@see VoiceCaptureService).\n  // This callback should be passed to the useVoiceCapturingIfMeetingIsRunning hook.\n  // It will be called with as soon as an internal buffer of 512 is full\n\n  const extractAndPersistVoiceEmotionsCallback = useCallback(async features => {\n    if (features.rms > THRESHOLD_RMS) {\n      // Push amplitude if no silence is detected\n      dataRef.current.push(...features.buffer);\n    } else {\n      // Push zeros if silence is detected\n      dataRef.current.push(...new Array(512).fill(0));\n    } // Every 2.1 seconds: Save the voice emotions and flush the buffer.\n\n\n    if (dataRef.current.length >= VoiceCaptureService.SAMPLE_RATE * 2.1) {\n      // Copy the data to a local variable and reset the global dataRef.\n      // This avoids an infinite loop if the callback is called faster than it executes.\n      // This is necessary because this is an async function with a race condition on dataRef.\n      const data = rmsNormalize(dataRef.current.slice(0, VoiceCaptureService.SAMPLE_RATE * 2.1));\n      dataRef.current = [];\n\n      if (Math.min(...data) === 0 && Math.max(...data) === 0) {\n        // Complete silence is reported as neutral\n        await dispatch(addVoiceEmotionScore({\n          score: 0.0,\n          meetingID,\n          raw: {\n            neutral: 1.0,\n            happy: 0.0,\n            sad: 0.0,\n            angry: 0.0,\n            fearful: 0.0,\n            disgusted: 0.0,\n            surprised: 0.0\n          }\n        }));\n      } else {\n        // Otherwise report predicted tensor probabilities\n        const input = new Tensor(\"float32\", Float32Array.from(data), [1, VoiceCaptureService.SAMPLE_RATE * 2.1]);\n        const results = await onnxSession.current.run({\n          input\n        });\n        const outputTensorProbabilities = softmax(Array.from(results.output.data));\n        const voiceEmotionObject = VOICE_EMOTIONS.reduce((obj, emotionName, index) => ({ ...obj,\n          [emotionName]: outputTensorProbabilities[index]\n        }), {\n          neutral: 0.0,\n          happy: 0.0,\n          sad: 0.0,\n          angry: 0.0,\n          fearful: 0.0,\n          disgusted: 0.0,\n          surprised: 0.0\n        });\n        await dispatch(addVoiceEmotionScore({\n          score: aggregateAndCalculateVoiceEmotionScore(voiceEmotionObject),\n          meetingID,\n          raw: voiceEmotionObject\n        }));\n      }\n    }\n  }, [meetingID, dataRef, dispatch]);\n  return [warmupModel, extractAndPersistVoiceEmotionsCallback];\n}\n\n_s6(useVoiceEmotionCapturing, \"9G9xzvtBDBbFiRCho8WAc+SyHEk=\", false, function () {\n  return [useAppDispatch, useAppSelector];\n});","map":{"version":3,"sources":["/Users/sanjayar/Desktop/moody-main copy 2/src/pages/meeting/hooks.tsx"],"names":["useAppDispatch","useAppSelector","useCallback","useEffect","useLayoutEffect","useRef","useState","ScreenCaptureService","fetchMeeting","setActiveMeeting","unwrapResult","FaceRecognitionService","addFaceExpressionScore","aggregateAndCalculateExpressionScore","aggregateAndCalculatePaulEkmanEmotionScore","addError","activeMeetingEnded","activeMeetingRunning","selectMeetingById","VoiceCaptureService","rmsNormalize","softmax","aggregateAndCalculateVoiceEmotionScore","VOICE_EMOTIONS","addVoiceEmotionScore","InferenceSession","window","ort","Tensor","useScreenCapturingIfMeetingIsRunning","videoRef","handleStopMeeting","dispatch","screenCaptureServiceRef","meetingRunning","startScreenCapturing","current","startCapturing","attachStreamToVideo","mediaStream","getTracks","addEventListener","e","message","stopCapturing","useEmotionDetection","canvasRef","meetingID","state","meetings","activeMeeting","detectionsRef","faceRecognitionServiceRef","initializeFaceDetection","loadModel","interval","syncDetections","setInterval","detectAllFaces","then","detections","length","score","raw","clearInterval","animationFrame","drawDetections","requestAnimationFrame","cancelAnimationFrame","getContext","clearRect","width","height","useFetchMeeting","id","notFound","setNotFound","fetch","result","meeting","useMeetingInformation","meetingEnded","meetingLoading","loading","meetingName","name","useVoiceCapturingIfMeetingIsRunning","callback","voiceCaptureServiceRef","startVoiceCapturing","audioDevice","startAnalyzer","stopVoiceCapturing","useVoiceEmotionCapturing","onnxSession","warmupModel","create","executionProviders","dataRef","THRESHOLD_RMS","extractAndPersistVoiceEmotionsCallback","features","rms","push","buffer","Array","fill","SAMPLE_RATE","data","slice","Math","min","max","neutral","happy","sad","angry","fearful","disgusted","surprised","input","Float32Array","from","results","run","outputTensorProbabilities","output","voiceEmotionObject","reduce","obj","emotionName","index"],"mappings":";;;;;;;AAAA,SAASA,cAAT,EAAyBC,cAAzB,QAA+C,kBAA/C;AACA,SACEC,WADF,EAEEC,SAFF,EAGEC,eAHF,EAIEC,MAJF,EAKEC,QALF,QAMO,OANP;AAOA,OAAOC,oBAAP,MAAiC,kCAAjC;AACA,SAASC,YAAT,EAAuBC,gBAAvB,QAA+C,8BAA/C;AAEA,SAASC,YAAT,QAA6B,kBAA7B;AACA,OAAOC,sBAAP,MAAmC,uCAAnC;AACA,SAASC,sBAAT,QAAuC,4CAAvC;AACA,SACEC,oCADF,EAEEC,0CAFF,QAGO,4CAHP;AAIA,SAASC,QAAT,QAAyB,wBAAzB;AACA,SACEC,kBADF,EAEEC,oBAFF,EAGEC,iBAHF,QAIO,kCAJP;AAUA,OAAOC,mBAAP,MAAgC,iCAAhC;AAEA,SAASC,YAAT,EAAuBC,OAAvB,QAAsC,aAAtC;AACA,SACEC,sCADF,EAGEC,cAHF,QAIO,yCAJP;AAKA,SAASC,oBAAT,QAAqC,yCAArC,C,CACA;AACA;;AACA,MAAMC,gBAAgB,GAAIC,MAAD,CAAgBC,GAAhB,CAAoBF,gBAA7C;AACA,MAAMG,MAAM,GAAIF,MAAD,CAAgBC,GAAhB,CAAoBC,MAAnC,C,CAEA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,oCAAT,CACLC,QADK,EAELC,iBAFK,EAGO;AAAA;;AACZ,QAAMC,QAAQ,GAAGhC,cAAc,EAA/B;AACA,QAAMiC,uBAAuB,GAAG5B,MAAM,EAAtC;AACA,QAAM6B,cAAc,GAAGjC,cAAc,CAACgB,oBAAD,CAArC;AAEA,QAAMkB,oBAAoB,GAAGjC,WAAW,CAAC,YAAY;AACnD,QAAIgC,cAAJ,EAAoB;AAClB,UAAI;AACFD,QAAAA,uBAAuB,CAACG,OAAxB,GAAkC,IAAI7B,oBAAJ,EAAlC;AACA,cAAM0B,uBAAuB,CAACG,OAAxB,CAAgCC,cAAhC,EAAN;AACA,cAAMJ,uBAAuB,CAACG,OAAxB,CAAgCE,mBAAhC,CACJR,QAAQ,CAACM,OADL,CAAN;AAGAH,QAAAA,uBAAuB,CAACG,OAAxB,CAAgCG,WAAhC,CACGC,SADH,GACe,CADf,EAEGC,gBAFH,CAEoB,OAFpB,EAE6BV,iBAF7B;AAGD,OATD,CASE,OAAOW,CAAP,EAAU;AACVV,QAAAA,QAAQ,CACNjB,QAAQ,CACN,oCACE2B,CAAC,CAACC,OADJ,GAEE,2BAHI,CADF,CAAR;AAOD;AACF;AACF,GArBuC,EAqBrC,CAACX,QAAD,EAAWD,iBAAX,EAA8BG,cAA9B,EAA8CJ,QAA9C,CArBqC,CAAxC,CALY,CA4BZ;;AACA3B,EAAAA,SAAS,CAAC,MAAM;AACd,WAAO,MAAM;AAAA;;AACX,+BAAA8B,uBAAuB,CAACG,OAAxB,gFAAiCQ,aAAjC;AACD,KAFD;AAGD,GAJQ,EAIN,CAACV,cAAD,CAJM,CAAT;AAMA,SAAOC,oBAAP;AACD;;GAvCeN,oC;UAIG7B,c,EAEMC,c;;;AAmCzB,OAAO,SAAS4C,mBAAT,CACLf,QADK,EAELgB,SAFK,EAGC;AAAA;;AACN,QAAMd,QAAQ,GAAGhC,cAAc,EAA/B;AACA,QAAMkC,cAAc,GAAGjC,cAAc,CAACgB,oBAAD,CAArC;AACA,QAAM8B,SAAiB,GAAG9C,cAAc,CACrC+C,KAAD,IAAWA,KAAK,CAACC,QAAN,CAAeC,aADY,CAAxC;AAGA,QAAMC,aAAa,GAAG9C,MAAM,CAK1B,EAL0B,CAA5B;AAMA,QAAM+C,yBAAyB,GAAG/C,MAAM,EAAxC,CAZM,CAcN;;AACAF,EAAAA,SAAS,CAAC,MAAM;AACd,UAAMkD,uBAAuB,GAAG,YAAY;AAC1CD,MAAAA,yBAAyB,CAAChB,OAA1B,GAAoC,IAAIzB,sBAAJ,CAClCmB,QAAQ,CAACM,OADyB,CAApC;AAGA,YAAMgB,yBAAyB,CAAChB,OAA1B,CAAkCkB,SAAlC,EAAN;AACD,KALD;;AAMAD,IAAAA,uBAAuB;AACxB,GARQ,EAQN,CAACvB,QAAD,CARM,CAAT,CAfM,CAyBN;;AACA3B,EAAAA,SAAS,CAAC,MAAM;AACd,QAAIoD,QAAJ;;AACA,UAAMC,cAAc,GAAG,YAAY;AACjC,UAAItB,cAAJ,EAAoB;AAClB,YAAI;AACFqB,UAAAA,QAAQ,GAAG7B,MAAM,CAAC+B,WAAP,CAAmB,YAAY;AACxC,kBAAML,yBAAyB,CAC5BhB,OADG,CACMsB,cADN,GAEHC,IAFG,CAEGC,UAAD,IAAiBT,aAAa,CAACf,OAAd,GAAwBwB,UAF3C,CAAN;;AAGA,gBAAIT,aAAa,CAACf,OAAd,CAAsByB,MAAtB,GAA+B,CAAnC,EAAsC;AACpC,oBAAM7B,QAAQ,CACZpB,sBAAsB,CAAC;AACrBkD,gBAAAA,KAAK,EAAEjD,oCAAoC,CACzCsC,aAAa,CAACf,OAD2B,CADtB;AAIrB2B,gBAAAA,GAAG,EAAEjD,0CAA0C,CAC7CqC,aAAa,CAACf,OAD+B,CAJ1B;AAOrBW,gBAAAA;AAPqB,eAAD,CADV,CAAd;AAWD;AACF,WAjBU,EAiBR,IAjBQ,CAAX;AAkBD,SAnBD,CAmBE,OAAOL,CAAP,EAAU;AACV,gBAAMV,QAAQ,CACZjB,QAAQ,CACN,mDAAmD2B,CAAC,CAACC,OAD/C,CADI,CAAd;AAKD;AACF;AACF,KA7BD;;AA+BAa,IAAAA,cAAc;AAEd,WAAO,MAAM;AACXQ,MAAAA,aAAa,CAACT,QAAD,CAAb;AACD,KAFD;AAGD,GAtCQ,EAsCN,CAACvB,QAAD,EAAWe,SAAX,EAAsBb,cAAtB,CAtCM,CAAT,CA1BM,CAkEN;;AACA9B,EAAAA,eAAe,CAAC,MAAM;AACpB,QAAI6D,cAAJ;;AACA,QAAI/B,cAAJ,EAAoB;AAClB,YAAMgC,cAAc,GAAG,MAAM;AAC3B,YAAI,CAAC,CAACpB,SAAS,CAACV,OAAhB,EAAyB;AACvBgB,UAAAA,yBAAyB,CAAChB,OAA1B,CAAmC8B,cAAnC,CACEf,aAAa,CAACf,OADhB,EAEEU,SAAS,CAACV,OAFZ;AAID;;AACD6B,QAAAA,cAAc,GAAGE,qBAAqB,CAACD,cAAD,CAAtC;AACD,OARD;;AASAD,MAAAA,cAAc,GAAGE,qBAAqB,CAACD,cAAD,CAAtC;AAEA,aAAO,MAAM;AAAA;;AACXE,QAAAA,oBAAoB,CAACH,cAAD,CAApB;AACA,8BAAAnB,SAAS,CAACV,OAAV,mGACIiC,UADJ,CACe,IADf,EAEE;AAFF,yFAEE;AACEC,QAAAA,SAHJ,CAGc,CAHd,EAGiB,CAHjB,EAGoBxB,SAAS,CAACV,OAAV,CAAkBmC,KAHtC,EAG6CzB,SAAS,CAACV,OAAV,CAAkBoC,MAH/D;AAID,OAND;AAOD;AACF,GAtBc,EAsBZ,CAAC1B,SAAD,EAAYZ,cAAZ,CAtBY,CAAf;AAuBD;;IA7FeW,mB;UAIG7C,c,EACMC,c,EACGA,c;;;AAyF5B,OAAO,SAASwE,eAAT,CAAyBC,EAAzB,EAAgD;AAAA;;AACrD,QAAM1C,QAAQ,GAAGhC,cAAc,EAA/B;AACA,QAAM,CAAC2E,QAAD,EAAWC,WAAX,IAA0BtE,QAAQ,CAAU,KAAV,CAAxC;AAEAH,EAAAA,SAAS,CAAC,MAAM;AACd,UAAM0E,KAAK,GAAG,YAAY;AACxB,YAAMC,MAAM,GAAG,MAAM9C,QAAQ,CAACxB,YAAY,CAACkE,EAAD,CAAb,CAA7B;AACA,YAAMK,OAAiC,GAAGrE,YAAY,CAACoE,MAAD,CAAtD;;AACA,UAAI,CAACC,OAAL,EAAc;AACZH,QAAAA,WAAW,CAAC,IAAD,CAAX;AACD,OAFD,MAEO;AACL5C,QAAAA,QAAQ,CAACvB,gBAAgB,CAACsE,OAAO,CAACL,EAAT,CAAjB,CAAR;AACAE,QAAAA,WAAW,CAAC,KAAD,CAAX;AACD;AACF,KATD;;AAWAC,IAAAA,KAAK;AAEL,WAAO,MAAM;AACX7C,MAAAA,QAAQ,CAACvB,gBAAgB,CAAC,IAAD,CAAjB,CAAR;AACD,KAFD;AAGD,GAjBQ,EAiBN,CAACuB,QAAD,EAAW0C,EAAX,CAjBM,CAAT;AAmBA,SAAO,CAACC,QAAD,CAAP;AACD;;IAxBeF,e;UACGzE,c;;;AAyBnB,OAAO,SAASgF,qBAAT,CACLN,EADK,EAE4C;AAAA;;AACjD,QAAMxC,cAAc,GAAGjC,cAAc,CAACgB,oBAAD,CAArC;AACA,QAAMgE,YAAY,GAAGhF,cAAc,CAACe,kBAAD,CAAnC;AACA,QAAMkE,cAAc,GAAGjF,cAAc,CAAE+C,KAAD,IAAWA,KAAK,CAACC,QAAN,CAAekC,OAA3B,CAArC;AACA,QAAMC,WAAW,GAAGnF,cAAc,CAC/B+C,KAAD;AAAA;;AAAA,iCAAW9B,iBAAiB,CAAC8B,KAAD,EAAQ0B,EAAR,CAA5B,uDAAW,mBAA8BW,IAAzC;AAAA,GADgC,CAAlC;AAIA,SAAO,CAACH,cAAD,EAAiBhD,cAAjB,EAAiC+C,YAAjC,EAA+CG,WAA/C,CAAP;AACD;;IAXeJ,qB;UAGS/E,c,EACFA,c,EACEA,c,EACHA,c;;;AAOtB,OAAO,SAASqF,mCAAT,CACLC,QADK,EAKL;AAAA;;AACA,QAAMC,sBAAsB,GAAGnF,MAAM,CAA6B,IAA7B,CAArC;AACA,QAAM2B,QAAQ,GAAGhC,cAAc,EAA/B;AACA,QAAMkC,cAAc,GAAGjC,cAAc,CAACgB,oBAAD,CAArC;AAEA,QAAMwE,mBAAmB,GAAGvF,WAAW,CACrC,MAAOwF,WAAP,IAAkE;AAChEF,IAAAA,sBAAsB,CAACpD,OAAvB,GAAiC,IAAIjB,mBAAJ,EAAjC;;AACA,QAAI;AAAA;;AACF,YAAMqE,sBAAsB,CAACpD,OAAvB,CAA+BC,cAA/B,CAA8CqD,WAA9C,CAAN;AACA,+BAAAF,sBAAsB,CAACpD,OAAvB,gFAAgCuD,aAAhC,CAA8CJ,QAA9C;AACA,uCAAOC,sBAAsB,CAACpD,OAA9B,2DAAO,uBAAgCG,WAAvC;AACD,KAJD,CAIE,OAAOG,CAAP,EAAU;AACVV,MAAAA,QAAQ,CACNjB,QAAQ,CACN,mCACE2B,CAAC,CAACC,OADJ,GAEE,2BAHI,CADF,CAAR;AAOD;AACF,GAhBoC,EAiBrC,CAAC4C,QAAD,EAAWvD,QAAX,CAjBqC,CAAvC;AAoBA,QAAM4D,kBAAkB,GAAG1F,WAAW,CAAC,YAAY;AACjD,QAAI;AAAA;;AACF,uCAAMsF,sBAAsB,CAACpD,OAA7B,2DAAM,uBAAgCQ,aAAhC,EAAN;AACD,KAFD,CAEE,OAAOF,CAAP,EAAU;AACVV,MAAAA,QAAQ,CAACjB,QAAQ,CAAC2B,CAAC,CAACC,OAAH,CAAT,CAAR;AACD;;AACD6C,IAAAA,sBAAsB,CAACpD,OAAvB,GAAiC,IAAjC;AACD,GAPqC,EAOnC,CAACJ,QAAD,CAPmC,CAAtC,CAzBA,CAkCA;;AACA7B,EAAAA,SAAS,CAAC,MAAM;AACd,WAAO,MAAM;AACXyF,MAAAA,kBAAkB;AACnB,KAFD;AAGD,GAJQ,EAIN,CAAC1D,cAAD,EAAiB0D,kBAAjB,CAJM,CAAT;AAMA,SAAO,CAACH,mBAAD,EAAsBG,kBAAtB,CAAP;AACD;;IA/CeN,mC;UAOGtF,c,EACMC,c;;;AAyCzB,OAAO,SAAS4F,wBAAT,GAGL;AAAA;;AACA,QAAMC,WAAW,GAAGzF,MAAM,CAAiC,IAAjC,CAA1B;AAEA,QAAM0F,WAAW,GAAG7F,WAAW,CAAC,YAAY;AAC1C4F,IAAAA,WAAW,CAAC1D,OAAZ,GAAsB,MAAMX,gBAAgB,CAACuE,MAAjB,CAC1B,8BAD0B,EAE1B;AAAEC,MAAAA,kBAAkB,EAAE,CAAC,MAAD;AAAtB,KAF0B,CAA5B;AAID,GAL8B,EAK5B,EAL4B,CAA/B;AAOA,QAAMjE,QAAQ,GAAGhC,cAAc,EAA/B;AACA,QAAM+C,SAAiB,GAAG9C,cAAc,CACrC+C,KAAD,IAAWA,KAAK,CAACC,QAAN,CAAeC,aADY,CAAxC,CAXA,CAeA;AACA;;AACA,MAAIgD,OAAO,GAAG7F,MAAM,CAAW,EAAX,CAApB,CAjBA,CAmBA;AACA;;AACA,QAAM8F,aAAa,GAAG,KAAtB,CArBA,CAuBA;AACA;AACA;;AACA,QAAMC,sCAAsC,GAAGlG,WAAW,CACxD,MAAOmG,QAAP,IAAkD;AAChD,QAAIA,QAAQ,CAACC,GAAT,GAAgBH,aAApB,EAAmC;AACjC;AACAD,MAAAA,OAAO,CAAC9D,OAAR,CAAgBmE,IAAhB,CAAqB,GAAGF,QAAQ,CAACG,MAAjC;AACD,KAHD,MAGO;AACL;AACAN,MAAAA,OAAO,CAAC9D,OAAR,CAAgBmE,IAAhB,CAAqB,GAAG,IAAIE,KAAJ,CAAU,GAAV,EAAeC,IAAf,CAAoB,CAApB,CAAxB;AACD,KAP+C,CAShD;;;AACA,QAAIR,OAAO,CAAC9D,OAAR,CAAgByB,MAAhB,IAA0B1C,mBAAmB,CAACwF,WAApB,GAAkC,GAAhE,EAAqE;AACnE;AACA;AACA;AACA,YAAMC,IAAc,GAAGxF,YAAY,CACjC8E,OAAO,CAAC9D,OAAR,CAAgByE,KAAhB,CAAsB,CAAtB,EAAyB1F,mBAAmB,CAACwF,WAApB,GAAkC,GAA3D,CADiC,CAAnC;AAGAT,MAAAA,OAAO,CAAC9D,OAAR,GAAkB,EAAlB;;AAEA,UAAI0E,IAAI,CAACC,GAAL,CAAS,GAAGH,IAAZ,MAAsB,CAAtB,IAA2BE,IAAI,CAACE,GAAL,CAAS,GAAGJ,IAAZ,MAAsB,CAArD,EAAwD;AACtD;AACA,cAAM5E,QAAQ,CACZR,oBAAoB,CAAC;AACnBsC,UAAAA,KAAK,EAAE,GADY;AAEnBf,UAAAA,SAFmB;AAGnBgB,UAAAA,GAAG,EAAE;AACHkD,YAAAA,OAAO,EAAE,GADN;AAEHC,YAAAA,KAAK,EAAE,GAFJ;AAGHC,YAAAA,GAAG,EAAE,GAHF;AAIHC,YAAAA,KAAK,EAAE,GAJJ;AAKHC,YAAAA,OAAO,EAAE,GALN;AAMHC,YAAAA,SAAS,EAAE,GANR;AAOHC,YAAAA,SAAS,EAAE;AAPR;AAHc,SAAD,CADR,CAAd;AAeD,OAjBD,MAiBO;AACL;AACA,cAAMC,KAAK,GAAG,IAAI5F,MAAJ,CAAW,SAAX,EAAsB6F,YAAY,CAACC,IAAb,CAAkBd,IAAlB,CAAtB,EAA+C,CAC3D,CAD2D,EAE3DzF,mBAAmB,CAACwF,WAApB,GAAkC,GAFyB,CAA/C,CAAd;AAIA,cAAMgB,OAAO,GAAG,MAAM7B,WAAW,CAAC1D,OAAZ,CAAoBwF,GAApB,CAAwB;AAAEJ,UAAAA;AAAF,SAAxB,CAAtB;AACA,cAAMK,yBAAmC,GAAGxG,OAAO,CACjDoF,KAAK,CAACiB,IAAN,CAAWC,OAAO,CAACG,MAAR,CAAelB,IAA1B,CADiD,CAAnD;AAGA,cAAMmB,kBAAyC,GAC7CxG,cAAc,CAACyG,MAAf,CACE,CACEC,GADF,EAEEC,WAFF,EAGEC,KAHF,MAIM,EACJ,GAAGF,GADC;AAEJ,WAACC,WAAD,GAAeL,yBAAyB,CAACM,KAAD;AAFpC,SAJN,CADF,EASE;AACElB,UAAAA,OAAO,EAAE,GADX;AAEEC,UAAAA,KAAK,EAAE,GAFT;AAGEC,UAAAA,GAAG,EAAE,GAHP;AAIEC,UAAAA,KAAK,EAAE,GAJT;AAKEC,UAAAA,OAAO,EAAE,GALX;AAMEC,UAAAA,SAAS,EAAE,GANb;AAOEC,UAAAA,SAAS,EAAE;AAPb,SATF,CADF;AAoBA,cAAMvF,QAAQ,CACZR,oBAAoB,CAAC;AACnBsC,UAAAA,KAAK,EAAExC,sCAAsC,CAACyG,kBAAD,CAD1B;AAEnBhF,UAAAA,SAFmB;AAGnBgB,UAAAA,GAAG,EAAEgE;AAHc,SAAD,CADR,CAAd;AAOD;AACF;AACF,GA5EuD,EA6ExD,CAAChF,SAAD,EAAYmD,OAAZ,EAAqBlE,QAArB,CA7EwD,CAA1D;AAgFA,SAAO,CAAC+D,WAAD,EAAcK,sCAAd,CAAP;AACD;;IA9GeP,wB;UAaG7F,c,EACSC,c","sourcesContent":["import { useAppDispatch, useAppSelector } from \"../../reduxHooks\";\nimport {\n  useCallback,\n  useEffect,\n  useLayoutEffect,\n  useRef,\n  useState,\n} from \"react\";\nimport ScreenCaptureService from \"../../media/ScreenCaptureService\";\nimport { fetchMeeting, setActiveMeeting } from \"../../meetings/meetingsSlice\";\nimport { Meeting as MeetingModel } from \"../../models\";\nimport { unwrapResult } from \"@reduxjs/toolkit\";\nimport FaceRecognitionService from \"../../meetings/FaceRecognitionService\";\nimport { addFaceExpressionScore } from \"../../meetings/audienceFaceExpressionSlice\";\nimport {\n  aggregateAndCalculateExpressionScore,\n  aggregateAndCalculatePaulEkmanEmotionScore,\n} from \"../../meetings/audienceFaceExpressionUtils\";\nimport { addError } from \"../../error/errorSlice\";\nimport {\n  activeMeetingEnded,\n  activeMeetingRunning,\n  selectMeetingById,\n} from \"../../meetings/meetingsSelectors\";\nimport {\n  FaceDetection,\n  FaceExpressions,\n  WithFaceExpressions,\n} from \"face-api.js\";\nimport VoiceCaptureService from \"../../media/VoiceCaptureService\";\nimport { MeydaFeaturesObject } from \"meyda\";\nimport { rmsNormalize, softmax } from \"../../utils\";\nimport {\n  aggregateAndCalculateVoiceEmotionScore,\n  PaulEkmanVoiceEmotion,\n  VOICE_EMOTIONS,\n} from \"../../meetings/speakerVoiceEmotionUtils\";\nimport { addVoiceEmotionScore } from \"../../meetings/speakerVoiceEmotionSlice\";\n// onnxruntime-web is included in public/index.html as <script>\n// .wasm files are currently not compatible with the create-react-app webpack config\nconst InferenceSession = (window as any).ort.InferenceSession;\nconst Tensor = (window as any).ort.Tensor;\n\n// Returns a callback to start the screen capturing and automatically cleans up the react components.\n// Does nothing if the meeting is stopped.\n// Note: In Safari you must start a screen capturing from a user gesture handler. This means that\n// you cannot ask for permissions immediately after loading the page. The user must explicitly click a button\n// to agree that he will be asked for permission.\nexport function useScreenCapturingIfMeetingIsRunning(\n  videoRef: React.MutableRefObject<HTMLVideoElement | null>,\n  handleStopMeeting: () => void\n): () => void {\n  const dispatch = useAppDispatch();\n  const screenCaptureServiceRef = useRef<ScreenCaptureService>();\n  const meetingRunning = useAppSelector(activeMeetingRunning);\n\n  const startScreenCapturing = useCallback(async () => {\n    if (meetingRunning) {\n      try {\n        screenCaptureServiceRef.current = new ScreenCaptureService();\n        await screenCaptureServiceRef.current.startCapturing();\n        await screenCaptureServiceRef.current.attachStreamToVideo(\n          videoRef.current!\n        );\n        screenCaptureServiceRef.current.mediaStream\n          .getTracks()[0]\n          .addEventListener(\"ended\", handleStopMeeting);\n      } catch (e) {\n        dispatch(\n          addError(\n            \"Cannot start screen capturing: \" +\n              e.message +\n              \". Try to reload the page.\"\n          )\n        );\n      }\n    }\n  }, [dispatch, handleStopMeeting, meetingRunning, videoRef]);\n\n  // Cleanup function\n  useEffect(() => {\n    return () => {\n      screenCaptureServiceRef.current?.stopCapturing();\n    };\n  }, [meetingRunning]);\n\n  return startScreenCapturing;\n}\n\nexport function useEmotionDetection(\n  videoRef: React.MutableRefObject<HTMLVideoElement | null>,\n  canvasRef: React.MutableRefObject<HTMLCanvasElement | null>\n): void {\n  const dispatch = useAppDispatch();\n  const meetingRunning = useAppSelector(activeMeetingRunning);\n  const meetingID: string = useAppSelector(\n    (state) => state.meetings.activeMeeting!\n  );\n  const detectionsRef = useRef<\n    WithFaceExpressions<{\n      detection: FaceDetection;\n      expressions: FaceExpressions;\n    }>[]\n  >([]);\n  const faceRecognitionServiceRef = useRef<FaceRecognitionService>();\n\n  // Initialize the face recognition service\n  useEffect(() => {\n    const initializeFaceDetection = async () => {\n      faceRecognitionServiceRef.current = new FaceRecognitionService(\n        videoRef.current!\n      );\n      await faceRecognitionServiceRef.current.loadModel();\n    };\n    initializeFaceDetection();\n  }, [videoRef]);\n\n  // Perform the detections every second\n  useEffect(() => {\n    let interval: number;\n    const syncDetections = async () => {\n      if (meetingRunning) {\n        try {\n          interval = window.setInterval(async () => {\n            await faceRecognitionServiceRef\n              .current!.detectAllFaces()\n              .then((detections) => (detectionsRef.current = detections));\n            if (detectionsRef.current.length > 0) {\n              await dispatch(\n                addFaceExpressionScore({\n                  score: aggregateAndCalculateExpressionScore(\n                    detectionsRef.current\n                  ),\n                  raw: aggregateAndCalculatePaulEkmanEmotionScore(\n                    detectionsRef.current\n                  ),\n                  meetingID,\n                })\n              );\n            }\n          }, 1000);\n        } catch (e) {\n          await dispatch(\n            addError(\n              \"Error while trying to save detected emotions: \" + e.message\n            )\n          );\n        }\n      }\n    };\n\n    syncDetections();\n\n    return () => {\n      clearInterval(interval);\n    };\n  }, [dispatch, meetingID, meetingRunning]);\n\n  // Draw the most recent detections with a high frame rate\n  useLayoutEffect(() => {\n    let animationFrame: number;\n    if (meetingRunning) {\n      const drawDetections = () => {\n        if (!!canvasRef.current) {\n          faceRecognitionServiceRef.current!.drawDetections(\n            detectionsRef.current,\n            canvasRef.current\n          );\n        }\n        animationFrame = requestAnimationFrame(drawDetections);\n      };\n      animationFrame = requestAnimationFrame(drawDetections);\n\n      return () => {\n        cancelAnimationFrame(animationFrame);\n        canvasRef.current\n          ?.getContext(\"2d\")\n          // eslint-disable-next-line react-hooks/exhaustive-deps\n          ?.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);\n      };\n    }\n  }, [canvasRef, meetingRunning]);\n}\n\nexport function useFetchMeeting(id: string): [boolean] {\n  const dispatch = useAppDispatch();\n  const [notFound, setNotFound] = useState<boolean>(false);\n\n  useEffect(() => {\n    const fetch = async () => {\n      const result = await dispatch(fetchMeeting(id));\n      const meeting: MeetingModel | undefined = unwrapResult(result);\n      if (!meeting) {\n        setNotFound(true);\n      } else {\n        dispatch(setActiveMeeting(meeting.id));\n        setNotFound(false);\n      }\n    };\n\n    fetch();\n\n    return () => {\n      dispatch(setActiveMeeting(null));\n    };\n  }, [dispatch, id]);\n\n  return [notFound];\n}\n\nexport function useMeetingInformation(\n  id: string\n): [boolean, boolean, boolean, string | undefined] {\n  const meetingRunning = useAppSelector(activeMeetingRunning);\n  const meetingEnded = useAppSelector(activeMeetingEnded);\n  const meetingLoading = useAppSelector((state) => state.meetings.loading);\n  const meetingName = useAppSelector(\n    (state) => selectMeetingById(state, id)?.name\n  );\n\n  return [meetingLoading, meetingRunning, meetingEnded, meetingName];\n}\n\nexport function useVoiceCapturingIfMeetingIsRunning(\n  callback: (features: Partial<MeydaFeaturesObject>) => void\n): [\n  (audioDevice?: string) => Promise<MediaStream | undefined>,\n  () => Promise<void>\n] {\n  const voiceCaptureServiceRef = useRef<VoiceCaptureService | null>(null);\n  const dispatch = useAppDispatch();\n  const meetingRunning = useAppSelector(activeMeetingRunning);\n\n  const startVoiceCapturing = useCallback(\n    async (audioDevice?: string): Promise<MediaStream | undefined> => {\n      voiceCaptureServiceRef.current = new VoiceCaptureService();\n      try {\n        await voiceCaptureServiceRef.current.startCapturing(audioDevice);\n        voiceCaptureServiceRef.current?.startAnalyzer(callback);\n        return voiceCaptureServiceRef.current?.mediaStream;\n      } catch (e) {\n        dispatch(\n          addError(\n            \"Cannot start voice capturing: \" +\n              e.message +\n              \". Try to reload the page.\"\n          )\n        );\n      }\n    },\n    [callback, dispatch]\n  );\n\n  const stopVoiceCapturing = useCallback(async () => {\n    try {\n      await voiceCaptureServiceRef.current?.stopCapturing();\n    } catch (e) {\n      dispatch(addError(e.message));\n    }\n    voiceCaptureServiceRef.current = null;\n  }, [dispatch]);\n\n  // Auto cleanup on component unmount or if the meeting is stopped\n  useEffect(() => {\n    return () => {\n      stopVoiceCapturing();\n    };\n  }, [meetingRunning, stopVoiceCapturing]);\n\n  return [startVoiceCapturing, stopVoiceCapturing];\n}\n\nexport function useVoiceEmotionCapturing(): [\n  () => Promise<void>,\n  (features: Partial<MeydaFeaturesObject>) => Promise<void>\n] {\n  const onnxSession = useRef<typeof InferenceSession | null>(null);\n\n  const warmupModel = useCallback(async () => {\n    onnxSession.current = await InferenceSession.create(\n      \"/onnx/voice_emotion_cnn.onnx\",\n      { executionProviders: [\"wasm\"] }\n    );\n  }, []);\n\n  const dispatch = useAppDispatch();\n  const meetingID: string = useAppSelector(\n    (state) => state.meetings.activeMeeting!\n  );\n\n  // Create a buffer for the audio data.\n  // This gets flushed every 2.1 seconds by the callback.\n  let dataRef = useRef<number[]>([]);\n\n  // Audio data below this threshold will be considered as silence\n  // This is useful to exclude disturbing background noises for example\n  const THRESHOLD_RMS = 0.002;\n\n  // Gets the features extracted by the audio analyzer (@see VoiceCaptureService).\n  // This callback should be passed to the useVoiceCapturingIfMeetingIsRunning hook.\n  // It will be called with as soon as an internal buffer of 512 is full\n  const extractAndPersistVoiceEmotionsCallback = useCallback(\n    async (features: Partial<MeydaFeaturesObject>) => {\n      if (features.rms! > THRESHOLD_RMS) {\n        // Push amplitude if no silence is detected\n        dataRef.current.push(...features.buffer!);\n      } else {\n        // Push zeros if silence is detected\n        dataRef.current.push(...new Array(512).fill(0));\n      }\n\n      // Every 2.1 seconds: Save the voice emotions and flush the buffer.\n      if (dataRef.current.length >= VoiceCaptureService.SAMPLE_RATE * 2.1) {\n        // Copy the data to a local variable and reset the global dataRef.\n        // This avoids an infinite loop if the callback is called faster than it executes.\n        // This is necessary because this is an async function with a race condition on dataRef.\n        const data: number[] = rmsNormalize(\n          dataRef.current.slice(0, VoiceCaptureService.SAMPLE_RATE * 2.1)\n        );\n        dataRef.current = [];\n\n        if (Math.min(...data) === 0 && Math.max(...data) === 0) {\n          // Complete silence is reported as neutral\n          await dispatch(\n            addVoiceEmotionScore({\n              score: 0.0,\n              meetingID,\n              raw: {\n                neutral: 1.0,\n                happy: 0.0,\n                sad: 0.0,\n                angry: 0.0,\n                fearful: 0.0,\n                disgusted: 0.0,\n                surprised: 0.0,\n              },\n            })\n          );\n        } else {\n          // Otherwise report predicted tensor probabilities\n          const input = new Tensor(\"float32\", Float32Array.from(data), [\n            1,\n            VoiceCaptureService.SAMPLE_RATE * 2.1,\n          ]);\n          const results = await onnxSession.current.run({ input });\n          const outputTensorProbabilities: number[] = softmax(\n            Array.from(results.output.data)\n          );\n          const voiceEmotionObject: PaulEkmanVoiceEmotion =\n            VOICE_EMOTIONS.reduce(\n              (\n                obj: PaulEkmanVoiceEmotion,\n                emotionName: keyof PaulEkmanVoiceEmotion,\n                index: number\n              ) => ({\n                ...obj,\n                [emotionName]: outputTensorProbabilities[index],\n              }),\n              {\n                neutral: 0.0,\n                happy: 0.0,\n                sad: 0.0,\n                angry: 0.0,\n                fearful: 0.0,\n                disgusted: 0.0,\n                surprised: 0.0,\n              }\n            );\n          await dispatch(\n            addVoiceEmotionScore({\n              score: aggregateAndCalculateVoiceEmotionScore(voiceEmotionObject),\n              meetingID,\n              raw: voiceEmotionObject,\n            })\n          );\n        }\n      }\n    },\n    [meetingID, dataRef, dispatch]\n  );\n\n  return [warmupModel, extractAndPersistVoiceEmotionsCallback];\n}\n"]},"metadata":{},"sourceType":"module"}