{"ast":null,"code":"var _jsxFileName = \"/Users/sanjayar/Desktop/moody-main/src/pages/meeting/VoiceVisualization.tsx\",\n    _s = $RefreshSig$();\n\nimport { Box, Paper, Typography } from \"@material-ui/core\";\nimport FrequencyBarVisualizerService from \"../../media/FrequencyBarVisualizerService\";\nimport { useEffect, useRef } from \"react\";\nimport { VOICE_EMOTIONS } from \"../../meetings/speakerVoiceEmotionUtils\";\nimport { useAppSelector } from \"../../reduxHooks\";\nimport { selectActiveMeetingSpeakerVoiceEmotionsLastN } from \"../../meetings/speakerVoiceEmotionSlice\";\nimport { Alert } from \"@material-ui/lab\";\nimport VoiceCaptureService from \"../../media/VoiceCaptureService\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nconst findMaxEmotion = voiceEmotion => {\n  if (!voiceEmotion) {\n    return undefined;\n  }\n\n  let maxScore = 0.0;\n  let maxEmotion = undefined;\n  VOICE_EMOTIONS.forEach(emotion => {\n    const emotionScore = voiceEmotion[emotion];\n\n    if (emotionScore > maxScore) {\n      maxScore = emotionScore;\n      maxEmotion = emotion;\n    }\n  });\n  return maxEmotion;\n};\n\nexport default function VoiceVisualization({\n  audioStream\n}) {\n  _s();\n\n  const canvasRef = useRef(null);\n  useEffect(() => {\n    let stopDrawing = () => {};\n\n    const startVisualization = async () => {\n      const AudioContext = window.AudioContext || window.webkitAudioContext;\n      stopDrawing = await new FrequencyBarVisualizerService(canvasRef.current, new AudioContext({\n        sampleRate: VoiceCaptureService.SAMPLE_RATE\n      }), audioStream).startDrawing();\n    };\n\n    startVisualization();\n    return () => {\n      stopDrawing();\n    };\n  }, [audioStream]);\n  const latestVoiceEmotion = useAppSelector(selectActiveMeetingSpeakerVoiceEmotionsLastN(1))[0];\n  const maxEmotion = findMaxEmotion(latestVoiceEmotion);\n  return /*#__PURE__*/_jsxDEV(Paper, {\n    children: /*#__PURE__*/_jsxDEV(Box, {\n      display: \"flex\",\n      pr: 2,\n      children: [/*#__PURE__*/_jsxDEV(\"canvas\", {\n        ref: canvasRef,\n        width: 700,\n        height: 375\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 67,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Box, {\n        ml: 6,\n        mt: 2,\n        children: [/*#__PURE__*/_jsxDEV(Typography, {\n          variant: \"h4\",\n          children: \"Predictions\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 69,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(Typography, {\n          variant: \"subtitle1\",\n          color: \"textSecondary\",\n          gutterBottom: true,\n          children: /*#__PURE__*/_jsxDEV(Box, {\n            lineHeight: 1.25,\n            children: [\"Voice emotions are captured every 2.1 seconds. Your voice is\", \" \", /*#__PURE__*/_jsxDEV(\"strong\", {\n              children: \"not\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 73,\n              columnNumber: 15\n            }, this), \" recorded. Only the aggregated emotions are saved.\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 71,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 70,\n          columnNumber: 11\n        }, this), latestVoiceEmotion ? /*#__PURE__*/_jsxDEV(_Fragment, {\n          children: VOICE_EMOTIONS.map(emotion => {\n            return /*#__PURE__*/_jsxDEV(Box, {\n              children: /*#__PURE__*/_jsxDEV(Box, {\n                display: \"inline-block\",\n                color: maxEmotion && maxEmotion === emotion ? \"primary.main\" : \"inherit\",\n                mt: 0.5,\n                borderBottom: maxEmotion && maxEmotion === emotion ? 1 : 0,\n                children: /*#__PURE__*/_jsxDEV(Typography, {\n                  variant: \"body1\",\n                  children: [/*#__PURE__*/_jsxDEV(\"strong\", {\n                    children: [emotion.toUpperCase(), \": \"]\n                  }, void 0, true, {\n                    fileName: _jsxFileName,\n                    lineNumber: 95,\n                    columnNumber: 25\n                  }, this), (latestVoiceEmotion[emotion] * 100).toFixed(2), \"%\"]\n                }, void 0, true, {\n                  fileName: _jsxFileName,\n                  lineNumber: 94,\n                  columnNumber: 23\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 82,\n                columnNumber: 21\n              }, this)\n            }, emotion, false, {\n              fileName: _jsxFileName,\n              lineNumber: 81,\n              columnNumber: 19\n            }, this);\n          })\n        }, void 0, false) : /*#__PURE__*/_jsxDEV(Alert, {\n          severity: \"info\",\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"No emotions have been tracked yet.\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 105,\n            columnNumber: 15\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 104,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 68,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 66,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 65,\n    columnNumber: 5\n  }, this);\n}\n\n_s(VoiceVisualization, \"BY3u7ZXyrPss4rubDBQLqhUmHGQ=\", false, function () {\n  return [useAppSelector];\n});\n\n_c = VoiceVisualization;\n\nvar _c;\n\n$RefreshReg$(_c, \"VoiceVisualization\");","map":{"version":3,"sources":["/Users/sanjayar/Desktop/moody-main/src/pages/meeting/VoiceVisualization.tsx"],"names":["Box","Paper","Typography","FrequencyBarVisualizerService","useEffect","useRef","VOICE_EMOTIONS","useAppSelector","selectActiveMeetingSpeakerVoiceEmotionsLastN","Alert","VoiceCaptureService","findMaxEmotion","voiceEmotion","undefined","maxScore","maxEmotion","forEach","emotion","emotionScore","VoiceVisualization","audioStream","canvasRef","stopDrawing","startVisualization","AudioContext","window","webkitAudioContext","current","sampleRate","SAMPLE_RATE","startDrawing","latestVoiceEmotion","map","toUpperCase","toFixed"],"mappings":";;;AAAA,SAASA,GAAT,EAAcC,KAAd,EAAqBC,UAArB,QAAuC,mBAAvC;AACA,OAAOC,6BAAP,MAA0C,2CAA1C;AACA,SAASC,SAAT,EAAoBC,MAApB,QAAkC,OAAlC;AACA,SAEEC,cAFF,QAGO,yCAHP;AAIA,SAASC,cAAT,QAA+B,kBAA/B;AACA,SAASC,4CAAT,QAA6D,yCAA7D;AAEA,SAASC,KAAT,QAAsB,kBAAtB;AACA,OAAOC,mBAAP,MAAgC,iCAAhC;;;;AAMA,MAAMC,cAAc,GAClBC,YADqB,IAEuB;AAC5C,MAAI,CAACA,YAAL,EAAmB;AACjB,WAAOC,SAAP;AACD;;AAED,MAAIC,QAAgB,GAAG,GAAvB;AACA,MAAIC,UAAmD,GAAGF,SAA1D;AAEAP,EAAAA,cAAc,CAACU,OAAf,CAAwBC,OAAD,IAA0C;AAC/D,UAAMC,YAAoB,GAAGN,YAAY,CAACK,OAAD,CAAzC;;AACA,QAAIC,YAAY,GAAGJ,QAAnB,EAA6B;AAC3BA,MAAAA,QAAQ,GAAGI,YAAX;AACAH,MAAAA,UAAU,GAAGE,OAAb;AACD;AACF,GAND;AAQA,SAAOF,UAAP;AACD,CAnBD;;AAqBA,eAAe,SAASI,kBAAT,CAA4B;AACzCC,EAAAA;AADyC,CAA5B,EAE0B;AAAA;;AACvC,QAAMC,SAAS,GAAGhB,MAAM,CAA2B,IAA3B,CAAxB;AACAD,EAAAA,SAAS,CAAC,MAAM;AACd,QAAIkB,WAAqB,GAAG,MAAM,CAAE,CAApC;;AACA,UAAMC,kBAAkB,GAAG,YAAY;AACrC,YAAMC,YAAY,GAChBC,MAAM,CAACD,YAAP,IAAwBC,MAAD,CAAgBC,kBADzC;AAEAJ,MAAAA,WAAW,GAAG,MAAM,IAAInB,6BAAJ,CAClBkB,SAAS,CAACM,OADQ,EAElB,IAAIH,YAAJ,CAAiB;AAAEI,QAAAA,UAAU,EAAElB,mBAAmB,CAACmB;AAAlC,OAAjB,CAFkB,EAGlBT,WAHkB,EAIlBU,YAJkB,EAApB;AAKD,KARD;;AASAP,IAAAA,kBAAkB;AAClB,WAAO,MAAM;AACXD,MAAAA,WAAW;AACZ,KAFD;AAGD,GAfQ,EAeN,CAACF,WAAD,CAfM,CAAT;AAgBA,QAAMW,kBAAmD,GAAGxB,cAAc,CACxEC,4CAA4C,CAAC,CAAD,CAD4B,CAAd,CAE1D,CAF0D,CAA5D;AAGA,QAAMO,UAAU,GAAGJ,cAAc,CAACoB,kBAAD,CAAjC;AAEA,sBACE,QAAC,KAAD;AAAA,2BACE,QAAC,GAAD;AAAK,MAAA,OAAO,EAAC,MAAb;AAAoB,MAAA,EAAE,EAAE,CAAxB;AAAA,8BACE;AAAQ,QAAA,GAAG,EAAEV,SAAb;AAAwB,QAAA,KAAK,EAAE,GAA/B;AAAoC,QAAA,MAAM,EAAE;AAA5C;AAAA;AAAA;AAAA;AAAA,cADF,eAEE,QAAC,GAAD;AAAK,QAAA,EAAE,EAAE,CAAT;AAAY,QAAA,EAAE,EAAE,CAAhB;AAAA,gCACE,QAAC,UAAD;AAAY,UAAA,OAAO,EAAC,IAApB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADF,eAEE,QAAC,UAAD;AAAY,UAAA,OAAO,EAAC,WAApB;AAAgC,UAAA,KAAK,EAAC,eAAtC;AAAsD,UAAA,YAAY,MAAlE;AAAA,iCACE,QAAC,GAAD;AAAK,YAAA,UAAU,EAAE,IAAjB;AAAA,uFAC+D,GAD/D,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAFF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBAFF,EASGU,kBAAkB,gBACjB;AAAA,oBACGzB,cAAc,CAAC0B,GAAf,CAAoBf,OAAD,IAA0C;AAC5D,gCACE,QAAC,GAAD;AAAA,qCACE,QAAC,GAAD;AACE,gBAAA,OAAO,EAAC,cADV;AAEE,gBAAA,KAAK,EACHF,UAAU,IAAIA,UAAU,KAAKE,OAA7B,GACI,cADJ,GAEI,SALR;AAOE,gBAAA,EAAE,EAAE,GAPN;AAQE,gBAAA,YAAY,EACVF,UAAU,IAAIA,UAAU,KAAKE,OAA7B,GAAuC,CAAvC,GAA2C,CAT/C;AAAA,uCAYE,QAAC,UAAD;AAAY,kBAAA,OAAO,EAAC,OAApB;AAAA,0CACE;AAAA,+BAASA,OAAO,CAACgB,WAAR,EAAT;AAAA;AAAA;AAAA;AAAA;AAAA,0BADF,EAEG,CAACF,kBAAkB,CAACd,OAAD,CAAlB,GAA8B,GAA/B,EAAoCiB,OAApC,CAA4C,CAA5C,CAFH;AAAA;AAAA;AAAA;AAAA;AAAA;AAZF;AAAA;AAAA;AAAA;AAAA;AADF,eAAUjB,OAAV;AAAA;AAAA;AAAA;AAAA,oBADF;AAqBD,WAtBA;AADH,yBADiB,gBA2BjB,QAAC,KAAD;AAAO,UAAA,QAAQ,EAAC,MAAhB;AAAA,iCACE,QAAC,UAAD;AAAY,YAAA,OAAO,EAAC,OAApB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBApCJ;AAAA;AAAA;AAAA;AAAA;AAAA,cAFF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,UADF;AAkDD;;GA3EuBE,kB;UAoBsCZ,c;;;KApBtCY,kB","sourcesContent":["import { Box, Paper, Typography } from \"@material-ui/core\";\nimport FrequencyBarVisualizerService from \"../../media/FrequencyBarVisualizerService\";\nimport { useEffect, useRef } from \"react\";\nimport {\n  PaulEkmanVoiceEmotion,\n  VOICE_EMOTIONS,\n} from \"../../meetings/speakerVoiceEmotionUtils\";\nimport { useAppSelector } from \"../../reduxHooks\";\nimport { selectActiveMeetingSpeakerVoiceEmotionsLastN } from \"../../meetings/speakerVoiceEmotionSlice\";\nimport { SpeakerVoiceEmotion } from \"../../models\";\nimport { Alert } from \"@material-ui/lab\";\nimport VoiceCaptureService from \"../../media/VoiceCaptureService\";\n\ntype VoiceVisualizationProps = {\n  audioStream: MediaStream;\n};\n\nconst findMaxEmotion = (\n  voiceEmotion: SpeakerVoiceEmotion\n): keyof PaulEkmanVoiceEmotion | undefined => {\n  if (!voiceEmotion) {\n    return undefined;\n  }\n\n  let maxScore: number = 0.0;\n  let maxEmotion: keyof PaulEkmanVoiceEmotion | undefined = undefined;\n\n  VOICE_EMOTIONS.forEach((emotion: keyof PaulEkmanVoiceEmotion) => {\n    const emotionScore: number = voiceEmotion[emotion];\n    if (emotionScore > maxScore) {\n      maxScore = emotionScore;\n      maxEmotion = emotion;\n    }\n  });\n\n  return maxEmotion;\n};\n\nexport default function VoiceVisualization({\n  audioStream,\n}: VoiceVisualizationProps): JSX.Element {\n  const canvasRef = useRef<HTMLCanvasElement | null>(null);\n  useEffect(() => {\n    let stopDrawing: Function = () => {};\n    const startVisualization = async () => {\n      const AudioContext =\n        window.AudioContext || (window as any).webkitAudioContext;\n      stopDrawing = await new FrequencyBarVisualizerService(\n        canvasRef.current!,\n        new AudioContext({ sampleRate: VoiceCaptureService.SAMPLE_RATE }),\n        audioStream\n      ).startDrawing();\n    };\n    startVisualization();\n    return () => {\n      stopDrawing();\n    };\n  }, [audioStream]);\n  const latestVoiceEmotion: SpeakerVoiceEmotion | undefined = useAppSelector(\n    selectActiveMeetingSpeakerVoiceEmotionsLastN(1)\n  )[0];\n  const maxEmotion = findMaxEmotion(latestVoiceEmotion);\n\n  return (\n    <Paper>\n      <Box display=\"flex\" pr={2}>\n        <canvas ref={canvasRef} width={700} height={375} />\n        <Box ml={6} mt={2}>\n          <Typography variant=\"h4\">Predictions</Typography>\n          <Typography variant=\"subtitle1\" color=\"textSecondary\" gutterBottom>\n            <Box lineHeight={1.25}>\n              Voice emotions are captured every 2.1 seconds. Your voice is{\" \"}\n              <strong>not</strong> recorded. Only the aggregated emotions are\n              saved.\n            </Box>\n          </Typography>\n          {latestVoiceEmotion ? (\n            <>\n              {VOICE_EMOTIONS.map((emotion: keyof PaulEkmanVoiceEmotion) => {\n                return (\n                  <Box key={emotion}>\n                    <Box\n                      display=\"inline-block\"\n                      color={\n                        maxEmotion && maxEmotion === emotion\n                          ? \"primary.main\"\n                          : \"inherit\"\n                      }\n                      mt={0.5}\n                      borderBottom={\n                        maxEmotion && maxEmotion === emotion ? 1 : 0\n                      }\n                    >\n                      <Typography variant=\"body1\">\n                        <strong>{emotion.toUpperCase()}: </strong>\n                        {(latestVoiceEmotion[emotion] * 100).toFixed(2)}%\n                      </Typography>\n                    </Box>\n                  </Box>\n                );\n              })}\n            </>\n          ) : (\n            <Alert severity=\"info\">\n              <Typography variant=\"body1\">\n                No emotions have been tracked yet.\n              </Typography>\n            </Alert>\n          )}\n        </Box>\n      </Box>\n    </Paper>\n  );\n}\n"]},"metadata":{},"sourceType":"module"}